{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fundamentals of Data Mining\n",
    "\n",
    "## Basic Probability Theory\n",
    "\n",
    "Flipping a coin.\n",
    "\n",
    "Frequentist say: \"Flip the coin many times, we expect it to be heads about half the time.\"\n",
    "\n",
    "Bayesian say: \"Quantify our uncertainty or belief about something.\"\n",
    "\n",
    "Bayes rule: \"bayesian\" is used to refer to inference methods that represents \"degrees of uncertainty\" using probability theory and which leverage Bayes' rule, to update the degree of certainty given data. Or, in laymans terms: \"update our belief based on prior belief and data so that we infer something with a certain degree of uncertainty.\"\n",
    "\n",
    "$$p(H=h | Y = y) = \\frac{p(H=h) p(Y=y | H=h)}{p(Y=y)}$$\n",
    "\n",
    "where $p(H=h|Y=y)$ is our updated belief (or \"posterior probability\") and $p(H=h)$ and $p(Y=y|H=h)$ are our prior belief (or \"prior probability\") and data (or \"likelihood\"), respectively. The denominator is just a normalizer; it often is not used; it is very intense to compute and therefore has to be computed with something like monte carlo methods.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8180df55a6c751d640a512e9acccb76e32a247f5c207f09e4b8101856c6a1078"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
