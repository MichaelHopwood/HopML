{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jackknife\n",
    "\n",
    "The jackknife was proposed by M.H. Quenouille in 1949, and later refined and given its current name by John Tukey in 1956. It is similar to the bootstrap in that it involves resampling, but instead of sampling with replacement, the method samples without replacement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedure\n",
    "\n",
    "**Definition:**  The jackknife samples are computed by leaving out one observation $X_i$ from $\\vec{x} = (x_1, ..., x_n)$ at a time: \n",
    "\n",
    "A jackknife sample looks like\n",
    "\n",
    "$$\\vec{x}_{(i)} = (x_1, x_2, ..., x_{i-1}, x_{i+1}, ..., x_n)$$\n",
    "\n",
    "The dimension of a jackknife sample is $m = n-1$. There are $n$ unique different jackknife samples (which is probably a limitation). \n",
    "\n",
    "Notice: **No sampling is needed to compute the $n$ jackknife samples!**\n",
    "\n",
    "The $i$th Jackknife replicate $\\hat{\\theta}_{(i)}$ is defined as the value of the estimator or statistic $s(.)$ evaluated at the $i$th Jackknife sample $$\\hat{\\theta}_{(i)} = s(\\vec{X}_{(i)}), \\forall i = 1, ..., n.$$\n",
    "\n",
    "**Example:** Let $\\vec{X} = (1,5,7,10,12)^\\prime$ and define $\\hat{\\theta} = s(\\vec{X}) = \\bar{X}$ (sample mean).\n",
    "\n",
    "Step 1: The jackknife samples are \n",
    "\n",
    "$\\vec{X}_{(1)} = (5,7,10,12)^\\prime$\n",
    "\n",
    "$\\vec{X}_{(2)} = (3,7,10,12)^\\prime$\n",
    "\n",
    "$\\vec{X}_{(3)} = (3,5,10,12)^\\prime$\n",
    "\n",
    "$\\vec{X}_{(4)} = (3,5,7,12)^\\prime$\n",
    "\n",
    "$\\vec{X}_{(5)} = (3,5,7,10)^\\prime$\n",
    "\n",
    "Notice: $n$ samples are generated, each of size $m=n-1$.\n",
    "\n",
    "The 5 Jackknife replicates are: \n",
    "\n",
    "$\\hat{\\theta}_{(1)} = \\frac{5+7+10+12}{4}$\n",
    "\n",
    "$\\hat{\\theta}_{(2)} = \\frac{3+7+10+12}{4}$\n",
    "\n",
    "$\\hat{\\theta}_{(3)} = \\frac{3+5+10+12}{4}$\n",
    "\n",
    "$\\hat{\\theta}_{(4)} = \\frac{3+5+7+12}{4}$\n",
    "\n",
    "$\\hat{\\theta}_{(5)} = \\frac{3+5+7+10}{4}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard error estimate\n",
    "\n",
    "Step 1: Compute the $n$ jackknife samples (see above)\n",
    "\n",
    "Step 2: Evlauate the $n$ Jackknife replications (see above)\n",
    "\n",
    "Step 3: Evaluate standard error estimate as $se_{jack} = [\\frac{n-1}{n} \\sum(\\hat{\\theta}_{(.)} - \\hat{\\theta}_{(i)})^2]^{1/2}$\n",
    "\n",
    "where $\\hat{\\theta}_{(.)} = \\frac{1}{n} \\sum_{i=1}^n \\hat{\\theta}_{(i)}$\n",
    "\n",
    "## Bias estimate\n",
    "\n",
    "Step 1: Compute the $n$ jackknife samples (see above)\n",
    "\n",
    "Step 2: Evlauate the $n$ Jackknife replications (see above)\n",
    "\n",
    "Step 3: Jackknife bias estimate is $bias_{jack} = (n-1) (\\hat{\\theta}_{.} - \\hat{\\theta})$ where $\\hat{\\theta}_{(.)} = \\frac{1}{n} \\sum_{i=1}^n \\hat{\\theta}_{(i)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Standard error of jackknife:', 1.6309506430300091, 'bias', 0.0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "x = [3,5,7,10,12]\n",
    "n = len(x)\n",
    "\n",
    "replications = []\n",
    "for i in range(len(x)):\n",
    "    xi = copy.copy(x)\n",
    "    # Remove current index's sample\n",
    "    xi.pop(i)\n",
    "    replication_i = sum(xi) / len(xi)\n",
    "    replications.append(replication_i)\n",
    "\n",
    "stat0 = np.mean(x)\n",
    "replications = np.array(replications)\n",
    "theta_dot = (1./n) * np.sum(replications)\n",
    "var = ( (n-1) / n ) * np.sum((theta_dot - replications)**2)\n",
    "se = np.sqrt(var)\n",
    "bias = (n-1) * (theta_dot - stat0)\n",
    "\n",
    "#print(\"Using python plugins\", \"variance:\", np.var(replications), \"std\", np.std(replications))\n",
    "\"Standard error of jackknife:\", se, \"bias\", bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationship with bootstrap\n",
    "\n",
    "When $n$ is small, it is easier (faster) to compute the n-Jackknife replications. However, the Jackknife uses less information (less samples) than the bootstrap. In fact, the jackknife is an approximator to the bootstrap. \n",
    "\n",
    "## Failure of the Jackknife\n",
    "\n",
    "The jackknife can faile if the estimate $\\hat{\\theta}$ is not smooth (i.e. a small change in the data can cause a large change in the statistic). An example of a simple non-smooth statistic is the median.\n",
    "\n",
    "Example: $\\vec{X} = (10,27,31,40,46,50,52,104,146)^\\prime$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[48.0, 48.0, 48.0, 48.0, 45.0, 43.0, 43.0, 43.0, 43.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Standard error of jackknife:',\n",
       " 6.681465057054626,\n",
       " 'bias',\n",
       " array([-20.44444444, -20.44444444, -20.44444444, -20.44444444,\n",
       "          3.55555556,  19.55555556,  19.55555556,  19.55555556,\n",
       "         19.55555556]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "x = [10,27,31,40,46,50,52,104,146]\n",
    "n = len(x)\n",
    "\n",
    "replications = []\n",
    "for i in range(len(x)):\n",
    "    xi = copy.copy(x)\n",
    "    # Remove current index's sample\n",
    "    xi.pop(i)\n",
    "    replication_i = np.median(xi)\n",
    "    replications.append(replication_i)\n",
    "\n",
    "print(replications)\n",
    "replications = np.array(replications)\n",
    "theta_dot = (1./n) * np.sum(replications)\n",
    "var = ( (n-1) / n ) * np.sum((theta_dot - replications)**2)\n",
    "se = np.sqrt(var)\n",
    "bias = (n-1) * (theta_dot - replications)\n",
    "\n",
    "#print(\"Using python plugins\", \"variance:\", np.var(replications), \"std\", np.std(replications))\n",
    "\"Standard error of jackknife:\", se, \"bias\", bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many duplicates in the replications. This maps down nine statistics down to three, caused by the nonsmooth statistic. The jackknife is not a good estimation method for estimating percentiles (such as the median), or when using any other non-smooth estimator. \n",
    "\n",
    "To resolve this issue, the method called **Delete-d jackknife** was created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete-d Jackknife\n",
    "\n",
    "The delete-d jackknife subsamples are computed by leaving out $d$ observations from $\\vec{X}$ at a time. This is the essence of cross validation!\n",
    "\n",
    "The dimension of the subsample is $n-d$. The number of possible subsamples now rises to $\\begin{pmatrix}n\\\\d\\\\\\end{pmatrix}$\n",
    "\n",
    "**Algorithm**\n",
    "\n",
    "Step 1: Compute all $\\begin{pmatrix}n\\\\d\\\\\\end{pmatrix}$ d-jackknife subsamples from $\\vec{x}$.\n",
    "\n",
    "Step 2: Evaluate the jackknife replications $\\hat{\\theta}_{(i)} = s(\\vec{x}_{(i)})$\n",
    "\n",
    "Step 3: Estimation of the s.e. (where $n=rd$, where $r$ is a constant)\n",
    "\n",
    "$$\\hat{se}_{d-jack} = \\{ \\frac{r}{\\begin{pmatrix}n\\\\d\\\\\\end{pmatrix}} \\sum_i (\\hat{\\theta}_{(i)} - \\hat{\\theta}_{.})^2 \\}^{1/2}$$\n",
    "\n",
    "where $\\hat{\\theta}_{.} = \\frac{\\sum_i \\theta_{(i)}}{\\begin{pmatrix}n\\\\d\\\\\\end{pmatrix}}$\n",
    "\n",
    "The inconsistency of the jackknife subsamples with non-smooth statistics can be fixed using delete-d jackknife subsamples.\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7c28e26739430500fec97d508cbac2e5d4a112deb445b412c4e69aa96f605479"
  },
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
