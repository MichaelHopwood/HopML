{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Bootstrapping\r\n",
    "\r\n",
    "**Can we estimate the mean of a distribution without using a parametric model?**\r\n",
    "\r\n",
    "Key idea is to first estimate the distribution non-parametrically, and then get an estimate of the mean.\r\n",
    "\r\n",
    "**What about the standard error of that estimator? How to get a C.I.**\r\n",
    "\r\n",
    "Bootstrapping!\r\n",
    "\r\n",
    "## Bootstrap principle\r\n",
    "\r\n",
    "## Empirical distribution\r\n",
    "\r\n",
    "Let $x_1, ..., x_n$ be an independent real-valued random variable with distribution $P$.\r\n",
    "\r\n",
    "Define a pdf $\\hat{P}$ by\r\n",
    "\r\n",
    "$$\\hat{P}(A) = \\frac{1}{n} \\sum_{i=1}^n I_A(x_i)$$\r\n",
    "\r\n",
    "where $I_A (x_i) = \\begin{cases}\r\n",
    "1 & if x_i \\in A\\\\\r\n",
    "0 & o.w.\\\\\r\n",
    "\\end{cases}$\r\n",
    "\r\n",
    "$\\hat{P}$ is called the empirical distribution of the sample $X$.  $\\hat{P}$ can be thought as the distribution which puts mass $\\frac{1}{n}$ on each observation $X_i$. It can be shown that $\\hat{P}$ is a nonparametric likelihood estimator of $P$. This justifies estimating $P$ by $\\hat{P}$ if no other information about $P$ is available.\r\n",
    "\r\n",
    "**Theorem:** Let $A \\leq \\mathbf{R}$ (s.t. $P(A)$ is defined, i.e. $A$ belongs to the Borel $\\sigma$-algebra), then $\\hat{P}(A) \\xrightarrow{} P(A)$ as $n \\xrightarrow{} \\infty$. This result can proved using the Law of Large Numbers. \r\n",
    "\r\n",
    "**Proof:**\r\n",
    "\r\n",
    "$$n \\hat{P}(A) = \\sum_{i=1}^n I_A (x_i) \\sim Bin(n, P(A))$$\r\n",
    "\r\n",
    "This is a binomial because of our indicator function above.  We then use the law of large numbers to say $\\hat{P}(A) \\xrightarrow{} P(A)$, its expectation, as $n\\xrightarrow{} \\infty$. In other words, the distribution $P(A)$ can be approximated by $\\hat{P}(A)$ equally well. for all $A \\in I$ where $I$ is the set of all intervals of $\\mathbf{R}$. This is the empirical distribution. \r\n",
    "\r\n",
    "## Empirical distribution function\r\n",
    "\r\n",
    "Move in the direction of a CDF. Let $x_1, ..., x_n \\sim F$ where $F(x) = P(X \\leq x)$. Now because we cna relate the $F$ to the $P$, which was defined above, we can relate to the content above.\r\n",
    "\r\n",
    "We can estimate $F$ with the empirical distribution function $\\hat{F}_n$, the CDF that puts mass $\\frac{1}{n}$ at each data point $x_i$.\r\n",
    "\r\n",
    "$$\\hat{F}_n (x) = \\frac{1}{n} \\sum_{i=1}^n I(X_i \\leq x)$$\r\n",
    "\r\n",
    "where $I(x_i \\leq x) = \\begin{cases}\r\n",
    "1 & if X_i \\leq x\\\\\r\n",
    "0 & o.w.\\\\\r\n",
    "\\end{cases}$\r\n",
    "\r\n",
    "According to **Glivenko-Cautelli theorem**\r\n",
    "\r\n",
    "$$sup_x |\\hat{F}_n(x) - F(x)| \\xrightarrow[a.s.]{} 0$$\r\n",
    "\r\n",
    "Here, $\\hat{F}_n(x) \\xrightarrow[a.s.]{} F(x)$ as $n \\xrightarrow{} \\infty$. This is called a **consistent** estimator of $F$. In fact, the convergence is fast.\r\n",
    "\r\n",
    "## Sampling from the empirical distribution $\\hat{F}_n$\r\n",
    "\r\n",
    "To recap, we have a distribution $F$ which we do not know. So, we can use the estimator $\\hat{F}_n$, and we know that this estimator is a consistent estimator of $F$. So, how do we get a sample from $\\hat{F}_n$?\r\n",
    "\r\n",
    "Suppose we want to draw an iid sample $\\vec{X}^\\star = (X_1^\\star, ..., X_n^\\star)^T$ from $\\hat{F}_n$. When sampling from $\\hat{F}_n$, the $i$th observation $X_i$ in the original sample is selected with probability $\\frac{1}{n}$. If we use this idea, we can define a two-step procedure to do our sampling.\r\n",
    "\r\n",
    "Step 1: Draw $i_1, i_2, ..., i_n$ independently from the uniform distribution. $\\{ 1, 2, 3, ..., n \\}$.\r\n",
    "\r\n",
    "Step 2: Set $X_j^\\star = X_{ij}$ and $\\vec{X}^\\star = (X_{i_1}^\\star, ..., X_{i_n}^\\star)^T$\r\n",
    "\r\n",
    "For example, let's say $\\vec{X} = (3,2,7,8,10,25)^T$ is a sample coming from a distribution that we do not know. Now, we want a sample from the empirical distribution $\\hat{F}_n$ of $X$. \r\n",
    "\r\n",
    "Step 1: Draw $i_1, i_2, i_3, i_4, i_5, i_6$ from the uniform $\\{ 1,2,3,4,5,6 \\}$. Assume that $i_1 = 6,  i_2=3, i_3 = 1, i_4 = 2, i_5=1, i_6 = 3$ comes from the first drawing of the uniform, for instance.\r\n",
    "\r\n",
    "Step 2: We assign $X_j^\\star = X_{ij}$. So, in our first sample $\\vec{X}_1^\\star = (x_{i_1}, x_{i_2}, x_{i_3}, x_{i_4}, x_{i_5}, x_{i_6}) = (X_6, X_3, X_1, X_2, X_1, X_3) = (25, 7, 3, 2, 3, 7)$\r\n",
    "\r\n",
    "Each sample must have $n$ samples! We sample with replacement from the original sample $X_1, X_2, ..., X_n$.\r\n",
    "\r\n",
    "So, sampling from $\\hat{F}_n$ is the same as saying sampling with replacement from the original sample.\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bootstrap principle\r\n",
    "\r\n",
    "Let $\\vec{X} = (X_1, ..., X_n)^T$ be a random sample from $F$. Let $\\theta = t(F)$ be some parameter of the distribution $F$. \r\n",
    "\r\n",
    "$\\hat{\\theta} = s(\\vec{X})$ is an estimate of $\\theta$.\r\n",
    "\r\n",
    "Example: $\\vec{X} = (X_1, ..., X_n) \\sim F$,\r\n",
    "\r\n",
    "$\\theta = \\mu ( = t(F))$, which is a parameter\r\n",
    "\r\n",
    "$\\hat{\\theta} = \\bar{X} (= s(\\vec{X}))$, which is a function of the sample, and is an estimator of $\\theta$\r\n",
    "\r\n",
    "To evaluate statistical properties (bias or standard error) of $\\hat{\\theta}$, we need to estimate the sampling distribution of $\\hat{\\theta}$. The bootstrap method mimics the data generating process by sampling an estimate $\\hat{F}_n$ of $F$. The role of the above real quantities is taken by their analogous quantities in the \"bootstrap world\". \r\n",
    "\r\n",
    "$\\vec{X}^\\star = (X_1^\\star, ..., X_n^\\star)^T$ is a bootstrap sample from $\\hat{F}_n$. \r\n",
    "\r\n",
    "$\\theta^\\star = t(\\hat{F}_n)$ is the parameter in the bootstrap world.\r\n",
    "\r\n",
    "$\\hat{\\theta}^\\star = s(\\vec{X}^\\star)$ is the bootstrap replication for $\\theta$\r\n",
    "\r\n",
    "So, we have our bootstrap sample data $\\vec{X}^\\star$ is found using sample with replacement. Then, we have $\\theta$ which we are trying to understand. We have $\\theta^\\star$ which is the parameter in the bootstrap world. $\\hat{\\theta}^\\star$ is the estimated $\\theta$.\r\n",
    "\r\n",
    "So, what is the sampling distribution of $\\hat{\\theta}$?  This is estimated by its bootstrap equivalent $\\hat{\\theta}^\\star$.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "n = 1000\r\n",
    "sets = 100\r\n",
    "i = np.random.uniform(0,1,(sets, n))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The bootstrap principal can be summarized as follows:\r\n",
    "\r\n",
    "**In the real world**, we see some unknown probabldy distribution and we have a sample, with the goal of getting a statistic from the underlying distribution.\r\n",
    "\r\n",
    "We have an unknown probability distribution (Usually denoted as $P$ or $F$) and an observed random sample $\\vec{x}$.\r\n",
    "\r\n",
    "$$P, F \\xrightarrow{} \\vec{x} = (x_1, ..., x_u)$$\r\n",
    "\r\n",
    "producing $\\hat{\\theta} = s(\\vec{x})$, which is the **statistic of interest**\r\n",
    "\r\n",
    "**In the bootstrap world**, we have an empirical distribution (usually denoted as $\\hat{P}$ or $\\hat{F}_n$) and a bootstrap sample $\\vec{x}^\\star$. The bootstrap sample is derived from the observed random sample $\\vec{x}$. In the bootstrap world, the observed random sample $\\vec{x}$ acts as the \"population\". Some people call the $\\vec{x}^\\star$ a \"sample of a sample\".\r\n",
    "\r\n",
    "$$\\hat{P}, \\hat{F}_n \\xrightarrow{} \\vec{x}^\\star = (x_1^\\star, ..., x_n^\\star)$$\r\n",
    "\r\n",
    "producing $\\hat{\\theta}^\\star = s(\\vec{x}^\\star)$, which is the **bootstrap replication**\r\n",
    "\r\n",
    "Even though the distribution of the boostrap sample $\\vec{x}^\\star$ is known, the evaluation of the exact bootstrap sampling distribution of $\\hat{\\theta}^\\star$ can still be intractable (aka, a tough problem). \r\n",
    "\r\n",
    "### Example: Bootstrap median\r\n",
    "\r\n",
    "Let's say our stat of interest is the median. Our bootstrap sample can still be generated and we can get the bootstrap median. But, what is the sampling distribution of the sample median?\r\n",
    "\r\n",
    "In general, the bootstrap estimate of the sampling distribution of $\\hat{\\theta}^\\star$ is computed using the _monte carlo method_. \r\n",
    "\r\n",
    "**Algorithm**\r\n",
    "\r\n",
    "Step 1: Draw $B$ independent bootstrap samples $\\vec{X}^{(\\star) (1)}, ..., \\vec{X}^{(\\star) (B)}$ from $\\hat{F}_n$ (i.e. samples of size $n$ (with replacement) repeated $B$ times)\r\n",
    "\r\n",
    "This will generate a lot of $\\hat{\\theta}^\\star$ and we can visualize it in a distribution.\r\n",
    "\r\n",
    "Step 2: Evaluate the bootstrap replications $\\hat{\\theta}^\\star = s(\\vec{X}^{\\star (b)})$, $b = 1, ..., B$\r\n",
    "\r\n",
    "Step 3: Estimate the sampling distribution of $\\hat{\\theta}$ by the empirical distribution of the bootstrap replications $\\hat{\\theta}^{\\star (1)}, ..., \\hat{\\theta}^{\\star (B)}$\r\n",
    "\r\n",
    "**Question: Why should bootstrap work?**\r\n",
    "\r\n",
    "Glivenko-Cantelli Theorem says that $\\hat{F}_n \\xrightarrow[a.s.]{} F$ as $n \\xrightarrow{} \\infty$. So, iid sampling from $\\hat{F}_n$ should be approximately the same as iid sampling from $F$ when $n$ is large.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Applications\r\n",
    "\r\n",
    "### Bootstrap for standard error (s.e.)\r\n",
    "\r\n",
    "Let $\\theta = s(\\vec{x})$ be an estimator for $\\theta$ and suppose we want to know the s.e. of $\\hat{\\theta}$. \r\n",
    "\r\n",
    "**Algorithm:**\r\n",
    "\r\n",
    "Step 1: Draw $B$ independent samples $\\vec{X}^{\\star (1)}, ..., \\vec{X}^{\\star (B)}$ from $\\hat{F}_n$.\r\n",
    "\r\n",
    "Step 2: Evaluate the bootstrap replications $\\hat{\\theta}^\\star = s(\\vec{X}^{\\star (b)})$, $b = 1, ..., B$\r\n",
    "\r\n",
    "Step 3: Estimate the s.e., $se(\\hat{\\theta})$, by the standard deviation of the $B$ replications.\r\n",
    "\r\n",
    "$$se_{boot}(\\hat{\\theta}) = [\\frac{1}{B-1} \\sum_{b=1}^B (\\hat{\\theta}^{\\star (b)} - \\hat{\\theta}^{\\star (o)})^2]^{1/2}$$\r\n",
    "\r\n",
    "where $\\hat{\\theta}^{\\star o} = \\frac{1}{B} \\sum_{b=1}^B \\hat{\\theta}^{\\star (b)}$\r\n",
    "\r\n",
    "Remark: $\\bar{\\hat{\\theta}}^\\star$ or $\\hat{\\theta}^{\\star (o)}$: mean of the bootstrap replications"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "import numpy as np\r\n",
    "from numpy.random import choice\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "n=1000\r\n",
    "rv = np.random.randint(0,10,n)\r\n",
    "\r\n",
    "# FINISH\r\n",
    "def bootstrap(samples, statistic_func, nboot=1000):\r\n",
    "    \"\"\"Conduct bootstrap statistic estimation, including the estimate, \r\n",
    "    standard error, and confidence interval\r\n",
    "\r\n",
    "    Parameters\r\n",
    "    ----------\r\n",
    "    samples : array (n,)\r\n",
    "        1D array of samples\r\n",
    "    statistic_func : function\r\n",
    "        Function which summarizes an array\r\n",
    "        theta = f(samples)\r\n",
    "        Should have parameter `axis` where a specification of 0 allows\r\n",
    "        row-wise operations.\r\n",
    "    nboot : int\r\n",
    "        Number of bootstrap samples\r\n",
    "    \"\"\"\r\n",
    "    # Draw nboot independent samples from the available samples\r\n",
    "    samples_star = choice(rv, size=(len(samples),nboot))\r\n",
    "    # Evaluate the bootstrap replications\r\n",
    "    theta_hat = statistic_func(samples_star, axis=0)\r\n",
    "    # Analyze!\r\n",
    "    # 1. Evaluate standard error, se(theta-hat)\r\n",
    "    theta_hat_star_dot = (1 / nboot) * np.sum(theta_hat)\r\n",
    "    se_boot = ((1 / (nboot - 1)) * np.sum(np.square(theta_hat - theta_hat_star_dot)) )**(1/2)\r\n",
    "    # 2. Visualize sampling distribution\r\n",
    "    plt.hist(samples_star)\r\n",
    "    plt.show()\r\n",
    "\r\n",
    "    return theta_hat, se_boot, \r\n",
    "\r\n",
    "bootstrap(rv, np.mean, nboot=100), np.std(rv)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.09593441099064097, 2.8456872632107695)"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Bootstrap estimate of bias\r\n",
    "\r\n",
    "Suppose we estimate the parameter $\\theta = t(F)$ by the statistic $\\hat{\\theta} = s(\\vec{x})$\r\n",
    "\r\n",
    "The bias of $\\hat{\\theta}$ is defined as \r\n",
    "\r\n",
    "$$bias(\\hat{\\theta}) = E(\\hat{\\theta}) - \\theta$$\r\n",
    "\r\n",
    "Recall: if $bias(\\hat{\\theta}) = 0$, then $E(\\hat{\\theta}) = \\theta$, and $\\hat{\\theta}$ is an unbiased estimator. \r\n",
    "\r\n",
    "Example: Let $\\theta = \\mu$, and $\\hat{\\theta} = \\bar{x}$.\r\n",
    "\r\n",
    "$E[\\bar{x}] = \\mu$, $\\bar{x}$ is an unbiased estimator for $\\mu$.\r\n",
    "\r\n",
    "Substituting the empirical distribution $\\hat{F}_n$ for $F$, the bootstrap estimate of the bias is \r\n",
    "$$\\hat{bias (\\hat{\\theta})} = bias^\\star (\\hat{\\theta}^\\star) = E^\\star [\\hat{\\theta}^\\star] - \\hat{\\theta} = \\hat{\\theta}^{\\star (o)} - \\hat{\\theta}$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Confidence Intervals\r\n",
    "\r\n",
    "From the sampling distribution of $\\hat{\\theta}$, we can construct CIs for $\\theta$\r\n",
    "\r\n",
    "**Standard CI**\r\n",
    "\r\n",
    "Suppose that $\\hat{\\theta}$ is approximately normally distributed with mean $\\theta$ and variance $se(\\hat{\\theta})^2$.\r\n",
    "\r\n",
    "An approximate $(1 - \\alpha) 100 \\%$ CI for $\\theta$ is $\\hat{\\theta}_L = \\hat{\\theta} - Z_{\\alpha/2} \\hat{se}_{boot}(\\hat{\\theta})$ and $\\hat{\\theta}_U = \\hat{\\theta} + Z_{\\alpha/2} \\hat{se}_{boot}(\\hat{\\theta})$, where $Z_\\alpha$ is the $\\alpha$ critical value of the standard normal.\r\n",
    "\r\n",
    "**Bootstrap t-interval**\r\n",
    "\r\n",
    "See function in Rizzo textbook - TODO: replicate it in python.\r\n",
    "\r\n",
    "Suppose that $\\hat{\\theta}$ is approximately normal distribution. Also, suppose that $\\hat{\\sigma}_n$ is an estimate of the standard deviation of $\\hat{\\theta}$. Therefore, $\\hat{\\sigma}_n = \\frac{s}{\\sqrt{n}}$ in the normal mean problem. We can also use the **delta theorem approximation** for $\\hat{\\sigma}_n$. \r\n",
    "\r\n",
    "Let $T = \\frac{\\hat{\\theta} - \\theta}{\\hat{\\sigma}_n}$ be the \"t - statistic\".\r\n",
    "\r\n",
    "We can also use the bootstrap appromimation of $\\hat{\\sigma}_n$!\r\n",
    "\r\n",
    "From the bootstrap samples $X^{\\star (b)}$, we calculate $T^{\\star (b)} = \\frac{\\hat{\\theta^{\\star (b)}} - \\theta}{\\hat{\\sigma}_n^\\star}$ as the $T$ counterpart.\r\n",
    "\r\n",
    "Then the bootstrap + CI for $\\theta$ is given by $[\\hat{\\theta} + C^\\star_{\\alpha /2} \\hat{\\sigma}_n, \\hat{\\theta} + C^\\star_{1 - \\alpha /2} \\hat{\\sigma}_n]$ where $C^\\star_p$ is the 100 $p$th percentile of $T^{\\star (b)}$\r\n",
    "\r\n",
    "**Bootstrap percentile interval**\r\n",
    "\r\n",
    "Let $\\hat{\\theta}^{\\star (1)}, \\hat{\\theta}^{\\star (B)}$ be a bootstrap sample. **Order** the bootstrap replicates $\\hat{\\theta}^\\star_{(1)}, \\hat{\\theta}^\\star_{(2)}, ..., \\hat{\\theta}^\\star_{(B)}$. Let $m = [\\frac{\\alpha}{2} \\times B]$, where $[u]$ is the largest integer less than or equal to $u$.\r\n",
    "\r\n",
    "An approximation $(1 - \\alpha) 100 \\%$ CI for $\\theta$ is $(\\hat{\\theta}_{(m)}^\\star, \\hat{\\theta}_{(B-m)}^\\star)$.\r\n",
    "\r\n",
    "While the standard CI and bootstrap t-interval need normal distribution specifications, the bootstrap percentile interval does not. \r\n",
    "\r\n",
    "In real networks, the number of nodes at distance $d > <d>$ drops rapidly"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.8 64-bit"
  },
  "interpreter": {
   "hash": "7c28e26739430500fec97d508cbac2e5d4a112deb445b412c4e69aa96f605479"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}