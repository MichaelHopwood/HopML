{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Linear Algebra Review\n",
    "\n",
    "Matrix transpose: $A_{ij}^T = A_{ji}$ and $(AB)^T = B^T A^T$\n",
    "\n",
    "Matrix (dot) product: $C = AB$\n",
    "\n",
    "Identity matrix $I$ has a diagonal of ones and the rest zero.\n",
    "\n",
    "Matrix inversion: $A^{-1} A = A A^{-1} =  I_n$\n",
    "\n",
    "$$Ax = b$$\n",
    "\n",
    "$$A^{-1} A x = A^{-1} b$$\n",
    "\n",
    "$$I_n x = A^{-1} b$$\n",
    "\n",
    "Invertability. We cannot invert a matrix if 1) more rows than columns or 2) more columns than rows, or 3) redundant rows (\"linear dependence\", \"low rank\")\n",
    "\n",
    "Norms L^p norm: \n",
    "\n",
    "L2 norm (p=2) is mos often used. It is a distance. \n",
    "\n",
    "Eigendecomposition: $A v = \\lambda v$\n",
    "\n",
    "If $\\lambda$ is eigenvalue of matrix $A$, there exists an eigenvector $V$ such that \n",
    "\n",
    "$$A = V diag(\\lambda) V^{-1}$$\n",
    "\n",
    "We can find $\\lambda$ by $\\lambda = \\frac{V^T A V}{V^T V}$\n",
    "\n",
    "Every real symmetric matrix has a real, orthogonal eigendecomposition $A = Q \\Lambda Q^T$.\n",
    "\n",
    "This will take two vectors on an $x_1, x_2$ space. When you multiply the matrix, on the direction of v_1, you scale it by $\\lambda_1$. This stretches the space.\n",
    "\n",
    "\n",
    "Trace: $Tr(A) = \\sum_i A_{i,i}$\n",
    "\n",
    "We can switch this around in any way.\n",
    "\n",
    "$$Tr(ABC) = Tr(CAB) = Tr(BCA)$$\n",
    "\n",
    "# Probability and Information Theory\n",
    "\n",
    "A pdf must be contained s.t. $\\forall x \\in x, p(x) \\geq 0$. Additionally, $\\sum_{x\\in x} p(x) = 1$ or $\\int p(x) dx = 1$.\n",
    "\n",
    "Computing a marginal probability with the **sum rule**\n",
    "\n",
    "$$p(x) = \\int p(x,y) dy$$\n",
    "\n",
    "\n",
    "Conditional probability: $P(y=y, x=x) = \\frac{P(y=y, x=x)}{P(x=x)}$\n",
    "\n",
    "Chain rule of probability: $P(x_1, ..., x_n) = P(x_1) \\pi_{i=1}^n P(x_i | x_1, ..., x_{(i-1)})$\n",
    "\n",
    "$P(x_1, x_2, x_3) = P(x_1) P(x_2, x_3 | x_1) = P(x_1) p(x_2) p(x_3 | x_1, x_2)$\n",
    "\n",
    "\n",
    "Independence: $p(x=x, y=y) = p(x=x)p(y=y)$\n",
    "\n",
    "Expectation: $E_{x\\sim P} [f(x)] = \\sum_x P(x) f(x)$\n",
    "\n",
    "Variance and covariance: $E(Z)^2 = Var(Z) + (E Z)^2$ where $Z=f(x) - E f(x)$\n",
    "\n",
    "$Cov(X,Y) = E(XY) - EX EY$\n",
    "\n",
    "F distribution is chi-squared divided by chi-squared\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7c28e26739430500fec97d508cbac2e5d4a112deb445b412c4e69aa96f605479"
  },
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
