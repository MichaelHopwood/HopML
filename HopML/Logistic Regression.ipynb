{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "## Summary\n",
    "\n",
    "A logistic regression model tries to model $P(Y|X)$. We use a logit transformation to make sure the $P(Y|X)$ is between 0 and 1. The linear function (used inside logit) is trained via maximum likelihood estimation.\n",
    "\n",
    "\n",
    "## Detailed summary\n",
    "\n",
    "$$\\log(\\frac{p(X)}{1 - p(X)}) = \\beta_0 + \\beta_1 X$$\n",
    "\n",
    "As $p(X)$ increases, the $\\frac{p(X)}{1 - p(X)}$ will increase monotonically. \n",
    "As $p(x)$ increases, the $\\beta_0 + \\beta_1 x$ increases monotonically.\n",
    "$p(x)$ is always between 0 and 1.\n",
    "\n",
    "We train this via MLE: describe the distribution of observing $Y | X$ where $$\\begin{cases} 0 & \\hbox{with probability } 1 - p(x)\\\\ 1 & \\hbox{with probability } p(x) \\\\\\end{cases}$$\n",
    "\n",
    "where $P(Y=1) = \\frac{e^{\\beta_0 + \\beta_1 x}}{1 + e^{\\beta_0 + \\beta_1 x}} = p(x)$.\n",
    "\n",
    "If $Y_i \\sim Bernuoilli(p(X_i))$, then $p(Y=k) = p^k(x) (1 - p(x))^{1 - k}$\n",
    "\n",
    "Given each sample is independent, then the likelihood is defined as the product (for all samples) of $p(Y=k)$\n",
    "\n",
    "$$L(\\hat{\\beta}) = \\Pi_{i=1}^n p(y_i = k) = \\Pi_{i=1}^n \\{ p(x_i)^y_i [1 - p(x_i)]^{1 - y_i} \\} = \\Pi_{i: y_i = 1} p(x_i) \\Pi_{i: y_i = 0} [1 - p(x_i)]$$\n",
    "\n",
    "From here, we can solve normally by taking log-likelihood and derivative equal to zero.\n",
    "\n",
    "The maximum likelihood is an optimization which allows us to solve $\\vec{\\beta}$.\n",
    "\n",
    "The coefficient describes the effect of parameter $X$ on the log-odds of the class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple classes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p_k(X) = Pr(Y=k|X) = \\frac{e^{\\beta_k^T X}}{\\sum_{j=1}^K e^{\\beta_k^T X}}$\n",
    "\n",
    "Let $p_k(x) = e^{\\beta_k^T x}$\n",
    "\n",
    "The log odds of class 2 and 3 can be found by $\\beta_k^\\star = \\beta_k - \\beta_K$. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def softmax(X):\n",
    "    return np.exp(X) / np.sum(np.exp(X), axis=0)\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y, learning_rate=0.01, num_iters=100):\n",
    "        pass\n",
    "\n",
    "    def forward(self, X):\n",
    "        pass\n",
    "\n",
    "\n",
    "def logistic_regression():\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7c28e26739430500fec97d508cbac2e5d4a112deb445b412c4e69aa96f605479"
  },
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
