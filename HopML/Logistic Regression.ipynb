{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "$$\\log(\\frac{p(X)}{1 - p(X)}) = \\beta_0 + \\beta_1 X$$\n",
    "\n",
    "As $p(X)$ increases, the $\\frac{p(X)}{1 - p(X)}$ will increase monotonically. \n",
    "As $p(x)$ increases, the $\\beta_0 + \\beta_1 x$ increases monotonically.\n",
    "$p(x)$ is always between 0 and 1.\n",
    "\n",
    "We train this via MLE: describe the distribution of observing $Y | X$ where $$\\begin{cases} 0 & \\hbox{with probability } 1 - p(x)\\\\ 1 & \\hbox{with probability } p(x) \\\\\\end{cases}$$\n",
    "\n",
    "where $P(Y=1) = \\frac{e^{\\beta_0 + \\beta_1 x}}{1 + e^{\\beta_0 + \\beta_1 x}} = p(x)$.\n",
    "\n",
    "If $Y_i \\sim Bernuoilli(p(X_i))$, then $p(Y=k) = p^k(x) (1 - p(x))^{1 - k}$\n",
    "\n",
    "Given each sample is independent, then the likelihood is defined as the product (for all samples) of $p(Y=k)$\n",
    "\n",
    "$$L(\\hat{\\beta}) = \\Pi_{i=1}^n p(y_i = k) = \\Pi_{i=1}^n \\{ p(x_i)^y_i [1 - p(x_i)]^{1 - y_i} \\} = \\Pi_{i: y_i = 1} p(x_i) \\Pi_{i: y_i = 0} [1 - p(x_i)]$$\n",
    "\n",
    "From here, we can solve normally by taking log-likelihood and derivative equal to zero.\n",
    "\n",
    "The maximum likelihood is an optimization which allows us to solve $\\vec{\\beta}$.\n",
    "\n",
    "The coefficient describes the effect of parameter $X$ on the log-odds of the class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple classes\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7c28e26739430500fec97d508cbac2e5d4a112deb445b412c4e69aa96f605479"
  },
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
